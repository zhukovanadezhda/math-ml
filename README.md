# Linear Algebra & Basic Math for Machine Learning

In this personal project, I'm exploring and rebuilding the basic concepts of linear algebra and the core mathematics that form the foundation of machine learning. I'm coding everything from scratch to deepen my understanding, and I hope sharing my journey may help others interested in the math behind ML algorithms.

## Project Overview

In modern machine learning, libraries like NumPy and TensorFlow often hide the underlying math. My aim here is to go back to the basics by implementing:

- **Core Vector and Matrix Operations:**  
  Starting with simple operations such as vector addition, scalar multiplication, dot products, and matrix multiplication.

- **Advanced Matrix Operations:**  
  Expanding to more complex tasks like transposition, inversion, calculating determinants, solving linear systems, and performing decompositions.

- **Eigenvalue and Eigenvector Computations:**  
  These are essential for grasping dimensionality reduction techniques such as PCA.

- **Integration into ML Algorithms:**  
  Ultimately, I hope to use these foundational math operations to build basic machine learning algorithms (e.g. linear regression, logistic regression, PCA, etc.)
